setwd("~/GitHub/streaming-analysis")
#THIS WILL BE APPENDED ONTO THE TASK 2 SCRIPT SO REQUIRES THE DATASET TO BE LOADED FIRST
#TODO - curently predicts on training set only - needto make a stream for the test set
library(ggplot2)
library(data.table)
library(RMOA)
library(stream)
#won't usea validation set here
df_test <- bind_rows(df_test,df_valid)
#ctrl <- MOAoptions(model = "OCBoost", randomSeed = 57, ensembleSize = 25,
#                   smoothingParameter = 0.5)
#ctrl <- MOAoptions(model = "HoeffdingTree", leafprediction = "MC",
#                   removePoorAtts = TRUE, binarySplits = TRUE, tieThreshold = 0.20)
#build online corrdinated boosting model
#mymodel <- HoeffdingTree(control = ctrl)
mymodel <- OzaBoost(baseLearner="trees.HoeffdingTree", ensemblesize=30)
# Create a stream
dfStream <-datastream_dataframe(data=as.data.table(df_train))
# define some variables to be used in the loop
chunk <- 100
turns <- (nrow(dfStream$data)/chunk)-1
turns <- floor(turns)
position <- chunk
#make a test stream
test_stream <- datastream_dataframe(data=as.data.table(df_test))
# define some variables to be used in the loop
test_chunk <- floor(100 / (nrow(df_train)/nrow(df_test)))
#turns <- (nrow(test_stream$data)/chunk)-1
#turns <- floor(turns)
test_position <- test_chunk
test_sample <- test_stream$get_points(test_stream, n = test_chunk,
outofpoints = c("stop", "warn", "ignore"))
## first sample (train) - retrieves first 100 records ##
sample <- dfStream$get_points(dfStream, n = chunk,
outofpoints = c("stop", "warn", "ignore"))
## Train the first chunk
myboostedclassifier <- trainMOA(model = mymodel,
formula = won ~.,
data = datastream_dataframe(sample))
## Do some prediction to test the model
predictions <- predict(myboostedclassifier, test_sample)
table(sprintf("Actuals: %s", test_sample$won),
sprintf("Predicted: %s", predictions))
# calculate accuracy
cat("Accuracy is: ", sum(predictions==test_sample$won)/nrow(test_sample)*100,"%")
# hold results in a vector
accuracies <- c()
test_stream$reset()
#train over the stream
for (i in 1:turns){
# next sample
sample <- dfStream$get_points(dfStream, n = chunk,
outofpoints = c("stop", "warn", "ignore"))
test_sample <- test_stream$get_points(test_stream, n = test_chunk,
outofpoints = c("stop", "warn", "ignore"))
## Update the trained model with the new chunks
myboostedclassifier <- trainMOA(model = myboostedclassifier$model,
formula = won ~ .,
data = datastream_dataframe(sample),
reset = FALSE,trace = FALSE)
cat("chunk: ",i,"\n")
predictions <- predict(myboostedclassifier, test_sample)
# calculate accuracy
accuracies[i] <- sum(predictions==test_sample$won)/nrow(test_sample)*100
cat(accuracies[i],"%","\n")
}
#evaluating the model
#####
#for (i in 1:turns) {
# next sample
#  test_sample <- test_stream$get_points(test_stream, n = test_chunk,
#                                outofpoints = c("stop", "warn", "ignore"))
#  predictions <- predict(myboostedclassifier, test_sample)
# calculate accuracy
#  accuracies[i] <- sum(predictions==test_sample$won)/nrow(test_sample)*100
#  cat(accuracies[i],"%","\n")
#}
#plot accuracies for each chunk
plot(accuracies,type='l',col='red',
xlab="Chunk Number",ylab="Accuracy",frame=FALSE)
#THIS WILL BE APPENDED ONTO THE TASK 2 SCRIPT SO REQUIRES THE DATASET TO BE LOADED FIRST
#TODO - curently predicts on training set only - needto make a stream for the test set
library(ggplot2)
library(data.table)
library(RMOA)
library(stream)
library(dplyr)
#won't usea validation set here
df_test <- bind_rows(df_test,df_valid)
#ctrl <- MOAoptions(model = "OCBoost", randomSeed = 57, ensembleSize = 25,
#                   smoothingParameter = 0.5)
#ctrl <- MOAoptions(model = "HoeffdingTree", leafprediction = "MC",
#                   removePoorAtts = TRUE, binarySplits = TRUE, tieThreshold = 0.20)
#build online corrdinated boosting model
#mymodel <- HoeffdingTree(control = ctrl)
mymodel <- OzaBoost(baseLearner="trees.HoeffdingTree", ensemblesize=30)
# Create a stream
dfStream <-datastream_dataframe(data=as.data.table(df_train))
# define some variables to be used in the loop
chunk <- 100
turns <- (nrow(dfStream$data)/chunk)-1
turns <- floor(turns)
position <- chunk
#make a test stream
test_stream <- datastream_dataframe(data=as.data.table(df_test))
# define some variables to be used in the loop
test_chunk <- floor(100 / (nrow(df_train)/nrow(df_test)))
#turns <- (nrow(test_stream$data)/chunk)-1
#turns <- floor(turns)
test_position <- test_chunk
test_sample <- test_stream$get_points(test_stream, n = test_chunk,
outofpoints = c("stop", "warn", "ignore"))
## first sample (train) - retrieves first 100 records ##
sample <- dfStream$get_points(dfStream, n = chunk,
outofpoints = c("stop", "warn", "ignore"))
## Train the first chunk
myboostedclassifier <- trainMOA(model = mymodel,
formula = won ~.,
data = datastream_dataframe(sample))
## Do some prediction to test the model
predictions <- predict(myboostedclassifier, test_sample)
table(sprintf("Actuals: %s", test_sample$won),
sprintf("Predicted: %s", predictions))
# calculate accuracy
cat("Accuracy is: ", sum(predictions==test_sample$won)/nrow(test_sample)*100,"%")
# hold results in a vector
accuracies <- c()
test_stream$reset()
#train over the stream
for (i in 1:turns){
# next sample
sample <- dfStream$get_points(dfStream, n = chunk,
outofpoints = c("stop", "warn", "ignore"))
test_sample <- test_stream$get_points(test_stream, n = test_chunk,
outofpoints = c("stop", "warn", "ignore"))
## Update the trained model with the new chunks
myboostedclassifier <- trainMOA(model = myboostedclassifier$model,
formula = won ~ .,
data = datastream_dataframe(sample),
reset = FALSE,trace = FALSE)
cat("chunk: ",i,"\n")
predictions <- predict(myboostedclassifier, test_sample)
# calculate accuracy
accuracies[i] <- sum(predictions==test_sample$won)/nrow(test_sample)*100
cat(accuracies[i],"%","\n")
}
#evaluating the model
#####
#for (i in 1:turns) {
# next sample
#  test_sample <- test_stream$get_points(test_stream, n = test_chunk,
#                                outofpoints = c("stop", "warn", "ignore"))
#  predictions <- predict(myboostedclassifier, test_sample)
# calculate accuracy
#  accuracies[i] <- sum(predictions==test_sample$won)/nrow(test_sample)*100
#  cat(accuracies[i],"%","\n")
#}
#plot accuracies for each chunk
plot(accuracies,type='l',col='red',
xlab="Chunk Number",ylab="Accuracy",frame=FALSE)
#source of data https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results
library(dplyr)
library(rjson)
library(caret)
library(randomForest)
library(ROCR)
library(dummies)
#read in the train and test datasets and combine
df1 <- read.csv('dota_dataset\\dota2Train.csv')
df2 <- read.csv('dota_dataset\\dota2Test.csv')
names(df2) <- names(df1)
df <- rbind(df1,df2)
rm(df1,df2)
#dataset exploration
#######
#the dataset has no column names and is quite sparse
View(head(df))
#also, the types are all wrong - they should all be factors
str(df)
#record number of rows and columns
paste('number of columns =' , ncol(df) , '. number of rows =', nrow(df))
#most columns are not names, but we have a json file availible to correct this later
names(df)
#assess class label distribution - it is quite close to even
table(df[,1])
#check for missing values (there are none)
sum(complete.cases(df))==nrow(df)
#check there are equal number of heroes present in each team (hero values for all rows should sum to zero)
sum((rowSums(df[5:ncol(df)]))) == 0
#convert to factors
#####
df[sapply(df, is.numeric)] <- lapply(df[sapply(df, is.numeric)], as.factor)
#add column names to thte first few columns (https://archive.ics.uci.edu/ml/datasets/Dota2+Games+Results)
names(df)[1:4] <- c('won','cluster_id','game_mode','game_type')
#populate the other column names
#load in json file and use it to populate column names
hero_names <- fromJSON(file ="dota_dataset\\heroes.json")
for ( i in c(1:length(hero_names$heroes))){
names(df)[i+4] <- hero_names$heroes[[i]]$name
}
#drop this column - it has the same value for every entry - must be a mandatory character
df <- df%>%
select(-c(lina, cluster_id , game_mode , game_type))
# select(-c(lina))
#make training and tst sets
#####
set.seed(57)
# Simple into train test and validation sets
index <- sample(c(1:3), size = nrow(df), replace = TRUE, prob = c(.8, .2, .2))
df_train <- df[index == 1,]
df_test <- df[index == 2,]
df_valid <- df[index == 3,]
#train up some classifiers and assess the result
#####
num_attributes <- ncol(df_train)
#build a parameter grid
# Random forest
mtry <- as.integer(c(num_attributes * 0.25, num_attributes / 3, num_attributes * 0.5, num_attributes * 0.8))
nodesize <- c( 3, 5, 20)
ntree <- c(200)
PG<- as.data.frame(expand.grid(mtry=mtry, nodesize=nodesize,
ntree=ntree, stringsAsFactors=F))
#train models
#####
for (i in c(1:nrow(PG))){
mtry <- PG[i, "mtry"]
nodesize <- PG[i, "nodesize"]
ntree <- PG[i, "ntree"]
temp_model <- randomForest(formula(df_train) , data=df_train, mtry=mtry, ntree=ntree, nodesize=nodesize)
predictions <- predict(temp_model , df_valid)
cm<- confusionMatrix(predictions,df_valid$won)
accuracy <- cm$overall['Accuracy']
PG[i,'Accuracy'] <- accuracy
print(i)
}
#THIS WILL BE APPENDED ONTO THE TASK 2 SCRIPT SO REQUIRES THE DATASET TO BE LOADED FIRST
#TODO - curently predicts on training set only - needto make a stream for the test set
library(ggplot2)
library(data.table)
library(RMOA)
library(stream)
#won't usea validation set here
df_test <- bind_rows(df_test,df_valid)
#ctrl <- MOAoptions(model = "OCBoost", randomSeed = 57, ensembleSize = 25,
#                   smoothingParameter = 0.5)
#ctrl <- MOAoptions(model = "HoeffdingTree", leafprediction = "MC",
#                   removePoorAtts = TRUE, binarySplits = TRUE, tieThreshold = 0.20)
#build online corrdinated boosting model
#mymodel <- HoeffdingTree(control = ctrl)
mymodel <- OzaBoost(baseLearner="trees.HoeffdingTree", ensemblesize=30)
# Create a stream
dfStream <-datastream_dataframe(data=as.data.table(df_train))
# define some variables to be used in the loop
chunk <- 100
turns <- (nrow(dfStream$data)/chunk)-1
turns <- floor(turns)
position <- chunk
#make a test stream
test_stream <- datastream_dataframe(data=as.data.table(df_test))
# define some variables to be used in the loop
test_chunk <- floor(100 / (nrow(df_train)/nrow(df_test)))
#turns <- (nrow(test_stream$data)/chunk)-1
#turns <- floor(turns)
test_position <- test_chunk
test_sample <- test_stream$get_points(test_stream, n = test_chunk,
outofpoints = c("stop", "warn", "ignore"))
## first sample (train) - retrieves first 100 records ##
sample <- dfStream$get_points(dfStream, n = chunk,
outofpoints = c("stop", "warn", "ignore"))
## Train the first chunk
myboostedclassifier <- trainMOA(model = mymodel,
formula = won ~.,
data = datastream_dataframe(sample))
## Do some prediction to test the model
predictions <- predict(myboostedclassifier, test_sample)
table(sprintf("Actuals: %s", test_sample$won),
sprintf("Predicted: %s", predictions))
# calculate accuracy
cat("Accuracy is: ", sum(predictions==test_sample$won)/nrow(test_sample)*100,"%")
# hold results in a vector
accuracies <- c()
test_stream$reset()
#train over the stream
for (i in 1:turns){
# next sample
sample <- dfStream$get_points(dfStream, n = chunk,
outofpoints = c("stop", "warn", "ignore"))
test_sample <- test_stream$get_points(test_stream, n = test_chunk,
outofpoints = c("stop", "warn", "ignore"))
## Update the trained model with the new chunks
myboostedclassifier <- trainMOA(model = myboostedclassifier$model,
formula = won ~ .,
data = datastream_dataframe(sample),
reset = FALSE,trace = FALSE)
cat("chunk: ",i,"\n")
predictions <- predict(myboostedclassifier, test_sample)
# calculate accuracy
accuracies[i] <- sum(predictions==test_sample$won)/nrow(test_sample)*100
cat(accuracies[i],"%","\n")
}
#evaluating the model
#####
#for (i in 1:turns) {
# next sample
#  test_sample <- test_stream$get_points(test_stream, n = test_chunk,
#                                outofpoints = c("stop", "warn", "ignore"))
#  predictions <- predict(myboostedclassifier, test_sample)
# calculate accuracy
#  accuracies[i] <- sum(predictions==test_sample$won)/nrow(test_sample)*100
#  cat(accuracies[i],"%","\n")
#}
#plot accuracies for each chunk
plot(accuracies,type='l',col='red',
xlab="Chunk Number",ylab="Accuracy",frame=FALSE)
