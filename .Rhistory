pub2 == population[i,j+1])$distance
distance <- distance + leg_distance[1]
print(leg_distance)
}
distance <- 0
for (j in (1:(ncol(population)-2))){
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
for(i in c(1:nrow(population))){
distance <- 0
for (j in (1:(ncol(population)-2))){
#print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
population$total_distance[i] <- distance
print(i)
}
i
j
j<-1
distance <- 0
for (j in (1:(ncol(population)-2))){
#print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
distance <- 0
for (j in (1:(ncol(population)-2))){
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
distance <- 0
for (j in (1:(ncol(population)-2))){
print(j)
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
filter(distances,pub1 == population[i,147])
View(pub_data)
min(disrtances$distance)
min(distances$distance)
max(distances$distance)
distance <- 0
for (j in (1:(ncol(population)-2))){
print(j)
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
str(distances)
population[i,j]
distances <- as.numeric(distances)
distances$pub1 <- as.numeric(distances$pub1)
distances$pub2 <- as.numeric(distances$pub2)
#find shortest route from brewery around all pubs and back to brewery again
#make initial population
population <- data.frame()
for(i in c(1:100)){
row <- c(nrow(pub_data), sample(c(1:nrow(pub_data)-1),nrow(pub_data)-1),nrow(pub_data))
population <- rbind(population,row)
}
colnames(population) <- c(1:ncol(population))
#find total travel distance for each individual (row)
population$total_distance <- rep(0,nrow(population))
for(i in c(1:nrow(population))){
distance <- 0
for (j in (1:(ncol(population)-2))){
print(j)
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
population$total_distance[i] <- distance
print(i)
}
for(i in c(1:nrow(population))){
distance <- 0
for (j in (1:(ncol(population)-2))){
print(j)
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
population$total_distance[i] <- distance
print(i)
}
filter(distances,pub1==1,pub2==94)
filter(distances,pub1==1,pub2==95)
filter(distances,pub1==1,pub2==93)
#genetic algorithm
#####
#find shortest route from brewery around all pubs and back to brewery again
#make initial population
population <- data.frame()
for(i in c(1:100)){
row <- c(nrow(pub_data), sample(c(1:nrow(pub_data)-1),nrow(pub_data)-1),nrow(pub_data))
population <- rbind(population,row)
}
colnames(population) <- c(1:ncol(population))
#find total travel distance for each individual (row)
population$total_distance <- rep(0,nrow(population))
for(i in c(1:nrow(population))){
distance <- 0
for (j in (1:(ncol(population)-2))){
print(j)
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
population$total_distance[i] <- distance
print(i)
}
filter(distances,pub1==1,pub2==187)
filter(distances,pub1==1,pub2==188)
names(distances) <- c("pub1","pub2","distance")
distances$pub1 <- round(as.numeric(distances$pub1))
distances$pub2 <- round(as.numeric(distances$pub2))
#genetic algorithm
#####
#find shortest route from brewery around all pubs and back to brewery again
#make initial population
population <- data.frame()
for(i in c(1:100)){
row <- c(nrow(pub_data), sample(c(1:nrow(pub_data)-1),nrow(pub_data)-1),nrow(pub_data))
population <- rbind(population,row)
}
colnames(population) <- c(1:ncol(population))
#find total travel distance for each individual (row)
population$total_distance <- rep(0,nrow(population))
for(i in c(1:nrow(population))){
distance <- 0
for (j in (1:(ncol(population)-2))){
print(j)
print(distance)
leg_distance <- filter(distances,pub1 == population[i,j] ,
pub2 == population[i,j+1])$distance
distance <- distance + leg_distance
}
population$total_distance[i] <- distance
print(i)
}
View(population)
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will
install.packages("FactoMineR")
library("FactoMineR")
data(wine)
str(df)
library("FactoMineR")
data(wine)
df <- wine[,c(1,2, 16, 22, 29, 28, 30,31)]
str(df)
res.famd <- FAMD(df, graph = FALSE)
res.famd
res.famd <- FAMD(df, graph = TRUE)
?str
View(df)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
View(df)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
str(df)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df['Location.ID'])
library(FactoMineR)
res.famd <- FAMD(df, graph = FALSE)
str(df)
df['Location.ID'] <- as.factor(as.character((df['Location.ID'])))
library(FactoMineR)
res.famd <- FAMD(df, graph = FALSE)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2,3)]
#df['Location.ID'] <- as.factor(as.character((df['Location.ID'])))
library(FactoMineR)
res.famd <- FAMD(df, graph = FALSE)
str(df)
table(df$Code)
data(wine)
str(wine)
rm(wine)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2,3)]
#df['Location.ID'] <- as.factor(as.character((df['Location.ID'])))
library(FactoMineR)
res.famd <- FAMD(df, graph = FALSE)
nrow(df)
nrow(complete.cases(df))
complete.cases(df)
sum(complete.cases(df))
nrow(df)
df[complete.cases(df)==F,]
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df[complete.cases(df)==F,]
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2,3)]
#df['Location.ID'] <- as.factor(as.character((df['Location.ID'])))
library(FactoMineR)
res.famd <- FAMD(df, graph = FALSE)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(as.character((df['Location.ID'])))
library(FactoMineR)
res.famd <- FAMD(df, graph = FALSE)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df['Location.ID'])
df['Location.ID']
str(df)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df$Location.ID)
library(FactoMineR)
res.famd <- FAMD(df, graph = FALSE)
?read.csv
read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df$Location.ID)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df$Location.ID)
library(FactoMineR)
res.famd <- FAMD(df, graph = TRUE)
res.famd <- FAMD(df, graph = TRUE)
fviz_famd_var(res.famd, repel = TRUE)
install.packages("factoextra")
fviz_famd_var(res.famd, repel = TRUE)
library(factoextra)
fviz_famd_var(res.famd, repel = TRUE)
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
str(df)
#quantititive variables
quanti.var <- get_famd_var(res.famd, "quanti.var")
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
#qualititive variables
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#qualititive variables
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = T)
quali.var
quanti.var
#qualititive variables
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
row.names(df)
length(row.names(df))
length(unique(row.names(df)))
#all variables
fviz_famd_var(res.famd, repel = TRUE)
eig.val <- get_eigenvalue(red.famd)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df$Location.ID)
df['Month'] <- as.factor(df$Month)
df['Weekday'] <- as.factor(df$Weekday)
library(FactoMineR)
library(factoextra)
res.famd <- FAMD(df, graph = TRUE)
#all variables
fviz_famd_var(res.famd, repel = TRUE)
#quantititive variables
quanti.var <- get_famd_var(res.famd, "quanti.var")
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
#qualititive variables
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
eig.val <- get_eigenvalue(red.famd)
eig.val <- get_eigenvalue(res.famd)
eig.val
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
fviz_famd_var(res.famd, repel = TRUE)
quanti.var <- get_famd_var(res.famd, "quanti.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
quanti.var <- get_famd_var(res.famd, "quanti.var")
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
fviz_famd_var(res.famd, repel = TRUE)
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_screeplot(res.famd)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df$Location.ID)
df['Month'] <- as.factor(df$Month)
df['Weekday'] <- as.factor(df$Weekday)
library(FactoMineR)
library(factoextra)
res.famd <- FAMD(df, graph = TRUE)
#all variables
fviz_famd_var(res.famd, repel = TRUE)
View(df)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df$Location.ID)
df['Month'] <- as.factor(df$Month)
df['Weekday'] <- as.factor(df$Weekday)
library(FactoMineR)
library(factoextra)
res.famd <- FAMD(df, graph = TRUE)
res.famd <- FAMD(df, graph = FALSE)
res.famd
quanti.var <- get_famd_var(res.famd, "quanti.var")
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
#quantititive variables
quanti.var <- get_famd_var(res.famd, "quanti.var")
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
fviz_famd_var(res.famd, col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
#qualititive variables
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
quali.var <- get_famd_var(res.famd, "quali.var")
quali.var
fviz_famd_var(res.famd, "quali.var", col.var = "contrib")
fviz_famd_var(res.famd, repel = TRUE)
res.famd <- FAMD(df, graph = TRUE)
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, "quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_hmfa_quali_biplot(res.famd)
View(df)
str(df)
?fviz_famd_var
fviz_famd_var(res.famd, c("quanti.var", "quali.var"), col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_famd_var(res.famd, choice=c("quanti.var", "quali.var"), col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
fviz_famd_var(res.famd, choice="quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
row.names(df)
length(row.names(df))
length(unique(row.names(df)))
fviz_famd_var(res.famd, choice="quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
quali.var
quali.var$cos2
quali.var
quali.coord
quali.var$coord
quali.var
quali.var$contrib
quanti.var$cos2
res.famd <- FAMD(df, graph = TRUE)
fviz_famd_var(res.famd, repel = TRUE)
fviz_famd_var(res.famd, repel = FALSE)
fviz_famd_var(res.famd, repel = TRUE)
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
str(df)
quali.var <- get_famd_var(res.famd, "quali.var")
fviz_famd_var(res.famd, choice="quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),repel=TRUE)
fviz_famd_var(res.famd, repel = TRUE)
df <- read.csv('C:\\Users\\Alex\\Documents\\jobs\\tvsquared\\assesment\\r_df.csv')
df <- df[,-c(1,2)]
df['Location.ID'] <- as.factor(df$Location.ID)
df['Month'] <- as.factor(df$Month)
df['Weekday'] <- as.factor(df$Weekday)
library(FactoMineR)
library(factoextra)
res.famd <- FAMD(df, graph = FALSE)
#all variables - most ueful plot so far
fviz_famd_var(res.famd, repel = TRUE)
#scree plot
#fviz_screeplot(res.famd)
#quantititive variables
quanti.var <- get_famd_var(res.famd, "quanti.var")
fviz_famd_var(res.famd, "quanti.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE)
#qualititive variables
#quali.var <- get_famd_var(res.famd, "quali.var")
#fviz_famd_var(res.famd, choice="quali.var", col.var = "contrib",
#              gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
#eig.val <- get_eigenvalue(res.famd)
quali.var <- get_famd_var(res.famd, "quali.var")
install.packages("corrplot")
corrplot(quali.var$cos2)
library(corrplot)
corrplot(quali.var$cos2)
fviz_famd_var(res.famd, choice="quali.var", col.var = "contrib",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))
# Chunk 1
library(dplyr)
library(rjson)
library(caret)
library(randomForest)
library(ROCR)
library(dummies)
#read in the train and test datasets and combine
df1 <- read.csv('dota_dataset\\dota2Train.csv')
df2 <- read.csv('dota_dataset\\dota2Test.csv')
names(df2) <- names(df1)
#combine the original datasets to a single dataframe
df <- rbind(df1,df2)
rm(df1,df2)
# Chunk 3
#record number of rows and columns
paste('number of columns =' , ncol(df) , '. number of rows =', nrow(df))
# Chunk 6
#check for missing values (there are none)
sum(complete.cases(df))==nrow(df)
#check there are equal number of heroes present in each team (hero values for all rows should sum to zero)
sum((rowSums(df[5:ncol(df)]))) == 0
# Chunk 7
df[sapply(df, is.numeric)] <- lapply(df[sapply(df, is.numeric)], as.factor)
# Chunk 8
#add column names to the first few columns
names(df)[1:4] <- c('won','cluster_id','game_mode','game_type')
#populate the other column names
#load in json file and use it to populate column names
hero_names <- fromJSON(file ="dota_dataset\\heroes.json")
for ( i in c(1:length(hero_names$heroes))){
names(df)[i+4] <- hero_names$heroes[[i]]$name
}
# Chunk 9
#drop unwanted columns
df <- df%>%
select(-c(lina, cluster_id , game_mode , game_type))
# Chunk 11
library(ggplot2)
p <- ggplot(iris, aes(x=Petal.Length,
y = Petal.Width,color=Species) )
p <- p+ geom_point(aes(shape=Species))
p <- p + xlab('Petal Length')
p <- p + ylab('Petal Width')
p <- p + theme_bw()
p
# Chunk 12
set.seed(57)
# Split into train test and validation sets
index <- sample(c(1:3), size = nrow(df), replace = TRUE, prob = c(.6, .2, .2))
df_train <- df[index == 1,]
df_test <- df[index == 2,]
df_valid <- df[index == 3,]
# Chunk 13
num_attributes <- ncol(df_train)
#build a parameter grid
# Random forest
mtry <- as.integer(c(num_attributes * 0.25, num_attributes / 3, num_attributes * 0.5, num_attributes * 0.8))
nodesize <- c( 3, 5, 20)
ntree <- c(200)
PG<- as.data.frame(expand.grid(mtry=mtry, nodesize=nodesize,
ntree=ntree, stringsAsFactors=F))
# Chunk 14
for (i in c(1:nrow(PG))){
mtry <- PG[i, "mtry"]
nodesize <- PG[i, "nodesize"]
ntree <- PG[i, "ntree"]
temp_model <- randomForest(formula(df_train) , data=df_train, mtry=mtry, ntree=ntree, nodesize=nodesize)
predictions <- predict(temp_model , df_valid)
cm<- confusionMatrix(predictions,df_valid$won)
accuracy <- cm$overall['Accuracy']
PG[i,'Accuracy'] <- accuracy
print(i)
}
# Chunk 15
#assess best model on test set
PG <- PG%>%
arrange(desc(Accuracy))
mtry <- PG[1, "mtry"]
nodesize <- PG[1, "nodesize"]
ntree <- PG[1, "ntree"]
best_model <- randomForest(formula(df_train) , data=df_train, mtry=mtry, ntree=ntree, nodesize=nodesize , importance=T)
predictions <- predict(temp_model , df_valid)
confusionMatrix(predictions,df_valid$won)
setwd("~/GitHub/streaming-analysis")
setwd("~/GitHub/streaming-analysis")
